
R version 4.4.1 (2024-06-14) -- "Race for Your Life"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> # Load necessary packages
> install.packages("TeenGrowth", repos = NULL, type = "source")
Installing package into '/home/k/kschaumberg/R_packages'
(as 'lib' is unspecified)
* installing *source* package 'TeenGrowth' ...
** using staged installation
** R
** data
*** moving datasets to lazyload DB
** byte-compile and prepare package for lazy loading
Failed to query server: Connection timed out
Warning in system("timedatectl", intern = TRUE) :
  running command 'timedatectl' had status 1
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded from temporary location
Failed to query server: Connection timed out
Warning in system("timedatectl", intern = TRUE) :
  running command 'timedatectl' had status 1
** testing if installed package can be loaded from final location
Failed to query server: Connection timed out
Warning in system("timedatectl", intern = TRUE) :
  running command 'timedatectl' had status 1
** testing if installed package keeps a record of temporary installation path
* DONE (TeenGrowth)
> library(TeenGrowth)
Failed to query server: Connection timed out
Warning message:
In system("timedatectl", intern = TRUE) :
  running command 'timedatectl' had status 1
> library(dplyr)

Attaching package: 'dplyr'

The following objects are masked from 'package:stats':

    filter, lag

The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union

> library(parallel)
> 
> # Load the split data
> load("Data/TeenGrowth_SimData_List_Split.RData")
> 
> # Define central values and conditions
> central_values <- c("mean", "max", "most_recent", "mean+most_recent")
> conditions <- list(
+   list(ci = 'User-Defined', upper_margin = 0.5, lower_margin = 0.5),
+   list(ci = 95, upper_margin = NULL, lower_margin = NULL),
+   list(ci = 99, upper_margin = NULL, lower_margin = NULL)
+ )
> 
> # Function to run forecasts with retry logic and enhanced error logging
> run_forecasts <- function(training_data, central_value, condition) {
+   attempt <- 1
+   max_attempts <- 3
+   success <- FALSE
+   forecast <- NULL
+   
+   while (!success && attempt <= max_attempts) {
+     tryCatch({
+       forecast <- if (!is.null(condition$ci)) {
+         forecast_bmi(training_data, 
+                      central_value = central_value, 
+                      ci = condition$ci)
+       } else {
+         forecast_bmi(training_data, 
+                      central_value = central_value, 
+                      upper_margin = condition$upper_margin, 
+                      lower_margin = condition$lower_margin)
+       }
+       success <- TRUE
+     }, error = function(e) {
+       message("Attempt ", attempt, ": ", e$message)
+       message("Central value: ", central_value)
+       message("Condition: ", toString(condition))
+       message("Error details: ", capture.output(str(e)))
+       message("Training data summary: ", capture.output(summary(training_data)))
+       attempt <- attempt + 1
+     })
+   }
+   return(forecast)
+ }
> 
> # Set up the number of cores to use
> total_memory_gb <- 100 # Adjusted total memory request
> memory_per_core_gb <- 5 # Estimated memory usage per core
> num_cores <- min(detectCores() - 1, total_memory_gb / memory_per_core_gb)
> 
> # Function to process a single split
> process_split <- function(split_data, split_index) {
+   training_data <- split_data$training_data
+   forecasts <- list()
+   
+   for (central_value in central_values) {
+     for (condition in conditions) {
+       condition_desc <- if (!is.null(condition$ci)) {
+         paste0("ci_", condition$ci)
+       } else {
+         "margin_0.5"
+       }
+       
+       forecast <- run_forecasts(training_data, central_value, condition)
+       
+       if (!is.null(forecast)) {
+         forecast <- forecast %>% filter(agemos > 60)
+         condition_key <- if (!is.null(condition$ci)) {
+           paste0(central_value, "_ci_", condition$ci)
+         } else {
+           paste0(central_value, "_margin_0.5")
+         }
+         forecasts[[condition_key]] <- forecast
+       }
+     }
+   }
+   
+   split_data$forecasts <- forecasts
+   return(split_data)
+ }
> 
> # Run the processing in parallel
> processed_splits <- mclapply(seq_along(TeenGrowth_SimData_List_Split), function(i) {
+   message("Processing split ", i, " of ", length(TeenGrowth_SimData_List_Split))
+   process_split(TeenGrowth_SimData_List_Split[[i]], i)
+ }, mc.cores = num_cores)
Processing split 1 of 20
Processing split 2 of 20
Processing split 3 of 20
Processing split 4 of 20
Processing split 5 of 20
Processing split 6 of 20
Processing split 7 of 20
Processing split 8 of 20
Processing split 9 of 20
Processing split 10 of 20
Processing split 11 of 20
Processing split 12 of 20
Processing split 13 of 20
Processing split 14 of 20
Processing split 15 of 20
Processing split 17 of 20
Processing split 16 of 20
Processing split 18 of 20
Processing split 20 of 20
Processing split 19 of 20
> 
> # Replace the original list with the processed splits
> TeenGrowth_SimData_List_Split <- processed_splits
> 
> # Save the processed data
> save(TeenGrowth_SimData_List_Split, file = "Data/TeenGrowth_SimData_List_Split_Processed.RData")
> message("All splits processed and data saved.")
All splits processed and data saved.
> 
> proc.time()
      user     system    elapsed 
120262.380     96.756  12516.242 
